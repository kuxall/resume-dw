{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c02df2",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da73d66a",
   "metadata": {},
   "source": [
    "Job listing for a java developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e026e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listing = '''\n",
    "Java Developer- job post\n",
    "Citi\n",
    "19,188 reviews\n",
    "Irving, TX\n",
    "$121,560 - $182,340 a year - Full-time\n",
    "You must create an Indeed account before continuing to the company website to apply\n",
    "\n",
    "Job details:\n",
    "\n",
    "Salary:\n",
    "\t$121,560 - $182,340 a year\n",
    "Job Type:\n",
    "\tFull-time\n",
    "\n",
    "The Applications Development Technology Lead Analyst is a senior level position responsible for establishing and implementing new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to lead applications systems analysis and programming activities.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "•\tPartner with multiple management teams to ensure appropriate integration of functions to meet goals as well as identify and define necessary system enhancements to deploy new products and process improvements\n",
    "•\tResolve variety of high impact problems/projects through in-depth evaluation of complex business processes, system processes, and industry standards\n",
    "•\tProvide expertise in area and advanced knowledge of applications programming and ensure application design adheres to the overall architecture blueprint\n",
    "•\tUtilize advanced knowledge of system flow and develop standards for coding, testing, debugging, and implementation\n",
    "•\tDevelop comprehensive knowledge of how areas of business, such as architecture and infrastructure, integrate to accomplish business goals\n",
    "•\tProvide in-depth analysis with interpretive thinking to define issues and develop innovative solutions\n",
    "•\tServe as advisor or coach to mid-level developers and analysts, allocating work as necessary\n",
    "•\tAppropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.\n",
    "\n",
    "Qualifications:\n",
    "\n",
    "•\t6-10 years of relevant experience in Apps Development or systems analysis role\n",
    "•\tExtensive experience system analysis and in programming of software applications\n",
    "•\tExperience in managing and implementing successful projects\n",
    "•\tSubject Matter Expert (SME) in at least one area of Applications Development\n",
    "•\tAbility to adjust priorities quickly as circumstances dictate\n",
    "•\tDemonstrated leadership and project management skills\n",
    "•\tConsistently demonstrates clear and concise written and verbal communication\n",
    "\n",
    "Education:\n",
    "\n",
    "\tBachelor’s degree/University degree or equivalent experience\n",
    "\tMaster’s degree preferred\n",
    "\n",
    "This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n",
    "\n",
    "Key Responsibilities:\n",
    "\n",
    "•\tWrite excellent-quality code based on functional requirements, while meeting agile implementation deadlines.\n",
    "•\tContribute to concept models, design and system architectures.\n",
    "•\tBuild, deploy, and test application components in a development environment during the implementation phase working with all layers of the application stack.\n",
    "•\tWork proactively & independently to address project requirements, and articulate issues/challenges with enough lead time to address project delivery risks\n",
    "•\tCreate and maintain appropriate documentation during development.\n",
    "•\tSupport/understand legacy applications as well as new development.\n",
    "•\tProviding expertise in technical analysis and solving technical issues during project delivery\n",
    "•\tFull Software Development Lifecycle\n",
    "•\tCode reviews, test case reviews and ensure code developed meets the requirements\n",
    "•\tComponent Design/ Coding/ Unit Testing/ Debugging\n",
    "•\tLevel 3 production support\n",
    "\n",
    "Knowledge/Experience:\n",
    "\n",
    "•\t10-12 years of strong core and/or web Java development\n",
    "•\t7-10 years of experience with SQL and relational databases; 1-2 years or NoSQL preferred.\n",
    "•\tExcellent analytical skills and problem-solving experience for implementation, debugging and testing\n",
    "•\tCandidate needs to be self-motivated and self-managing; he will need to frequently interact and collaborate with colleagues in other teams to achieve common goals\n",
    "\n",
    "Skills Required\n",
    "\n",
    "•\tExperience in Object Oriented Development, writing and translating use cases and requirements.\n",
    "•\tUnix + Shell Scripting\n",
    "•\tAt least one Unit Testing Framework (jUnit or equivalent)\n",
    "\t\n",
    "Nice to Have\n",
    "•\t2-3 years of strong Big Data ecosystem experience (desired)\n",
    "•\t2-3 years of Python experience (nice to have)\n",
    "•\tSolid experience with frameworks like Spring, Spring Batch\n",
    "•\tFunctional Programming skills like Clojure, Scala\n",
    "•\tReactive Architecture, Apache Open Source Big Data toolset, Data Modelling, Warehousing, Data Governance\n",
    "\t-\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140c6e1",
   "metadata": {},
   "source": [
    "Job listing for an AI Researcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e58661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_listing = '''\n",
    "# Qualification and Experience\n",
    "\n",
    "# Completed bachelor in computer science or related field\n",
    "# Minimum 2 years of working experience in the field of AI\n",
    "# Required skills/Competencies\n",
    "\n",
    "# Good knowledge of the Mathematical concepts required for the AI algorithm understanding (Probability, Statistics, Calculus, Linear Algebra) \n",
    "# Proficient in python and anyone deep learning framework\n",
    "# Key Responsibilities\n",
    "\n",
    "# Literature review of the research paper, write up the critical analysis, and present that to the team. \n",
    "# Reproduce the result of the research paper either by implementing it from scratch or using the open-source codebase. \n",
    "# Find out the research gaps, formulate the hypothesis to overcome the research gaps, and verify the hypothesis experimentally and/or theoretically. \n",
    "# Proper documentation of the experimentation setup, results, architecture diagram, and other relevant information. \n",
    "# Conduct knowledge-sharing sessions and instruct AI classes (ML, DL, CV & NLP)\n",
    "# Assist in the Fusemachine’s AI project (outside of the research team)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44105fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_txt1 = '''\n",
    "Name: John Smith\n",
    "\n",
    "Contact Information:\n",
    "\n",
    "Email: johnsmith@email.com\n",
    "Phone: (123) 456-7890\n",
    "LinkedIn: linkedin.com/in/johnsmith\n",
    "\n",
    "Summary:\n",
    "A highly skilled and experienced full stack developer with a strong background in software engineering principles and hands-on experience in developing and maintaining complex financial software applications. With a Bachelor's degree in Computer Science and 7 years of experience in the industry, I possess the technical expertise to design, implement and maintain software applications that enable measuring and managing the risk of loan and investment portfolios.\n",
    "\n",
    "Skills:\n",
    "\tStrong understanding of software engineering principles – design, development, and operations\n",
    "\tProficient in Java, Python, and AWS\n",
    "\tExperience building resilient and scalable software that is easily portable to various computing infrastructures – on-prem, cloud\n",
    "\tAbility to motivate, teach and train other team members\n",
    "\tExperience in the financial industry, especially mortgages\n",
    "\tExposure to quantitative finance and data science\n",
    "\tExposure to Big Data technologies\n",
    "\n",
    "Knowledge:\n",
    "\n",
    "•\tStrong understanding of software engineering principles – design, development, and operations\n",
    "•\tExperience building resilient and scalable software that is easily portable to various computing infrastructures – on-prem, cloud\n",
    "•\tExperience in the financial industry, especially mortgages\n",
    "•\tExposure to quantitative finance and data science\n",
    "•\tExposure to Big Data technologies\n",
    "\n",
    "Work Experience:\n",
    "\n",
    "Java Developer - XYZ Company, Dallas, TX (2018 - Present)\n",
    "\n",
    "\tDesign, develop, and maintain complex financial software applications using Java, Python, and AWS technologies\n",
    "\tCollaborate with modeling, Information Technology, and business teams to ensure software systems are robust, scalable, and fault-tolerant\n",
    "\tEnhance existing design, improve code quality, and system efficiency\n",
    "\tBuild reusable and scalable frameworks to enable other developers to solve problems at a high level of abstraction (API/Library/Service)\n",
    "\tProvide strong technical leadership to junior members of the team\n",
    "\n",
    "Software Engineer - ABC Company, Austin, TX (2016 - 2018)\n",
    "\n",
    "\tDeveloped and maintained software applications for clients in various industries\n",
    "\tCollaborated with team members to design and implement software solutions using Java and Python\n",
    "\tConducted code reviews to ensure high code quality and adherence to software engineering principles\n",
    "\n",
    "Academics:\n",
    "\n",
    "\tBachelor's degree in Computer Science, University of Texas at Austin (2016)\n",
    "\tAWS Certified Developer-Associate certification\n",
    "\n",
    "Certifications:\n",
    "\n",
    "AWS Certified Developer - Associate (2019)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7edc6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_txt2 = '''\n",
    "Utsav Maskey\n",
    "AI / ML Enthusiast | +977 9863475127\n",
    "maskeyutsav@gmail.com | https://www.linkedin.com/in/utsav-maskey | https://huggingface.co/Sakonii/ Permanent Address: New Baneshwor-31, Kumud Devkota Marg, Kathmandu 44600, NP\n",
    "SUMMARY / SKILLS\n",
    "Practical machine-learning enthusiast, eager to contribute and avail in data driven fields. Intermediate understanding and proficiency of platforms for effective machine-learning including Pytorch, Pandas, R and spreadsheets; with mild experience in Web-development including FastAPI, Flask, MongoDB, Django and SQL. Marginally presuming yet open-minded person, motivated to learn, grow and excel in disciplines that employ statistical intelligence.\n",
    "EXPERIENCE / PROJECTS\n",
    "Information Language Processing & Research Lab, Researcher, Kathmandu University February 2022 – July 2022\n",
    "• Worked on projects aimed at training Large Language Models (LLMs) on the Nepali language including: distilbert-base-nepali, deberta-base-nepali and distilgpt2-nepali.\n",
    "Supercomputer Center Kathmandu University, ML Volunteer, Kathmandu University March 2022 – Present\n",
    "• Aided researchers and enthusiasts with the use of High-Performance Computing (HPC) resources.\n",
    "• Conducted workshops regarding server configuration and model training on remote distributed using Slurm Workload Manager.\n",
    "Ocular Parking System, Semester Project December 2019 – March 2020\n",
    "• A computer vision-based system that extracts real-time information on parking lot vacancy and occupancy (Number of available\n",
    "parking spots), and displays it in an interactive leaflet map.\n",
    "• Implemented on Python using Pytorch, OpenCV, Detectron and Folium map.\n",
    "Class Routine Management, Semester Project April 2021 – August 2021\n",
    "• Aims at automating class’ routine schedules by reducing the hassle of finding vacant classrooms in a large institution, caused due to\n",
    "unnoticed changes in routine. It is a web platform for college routine management, class placement and its arrangement.\n",
    "• Backend implemented on Python using FastAPI, PostgreSQL (using TortoiseORM) and ReactJS for Frontend.\n",
    "Other Pet Projects: Shashin-finder: Search for images in a folder by photo description, tags or objects present.\n",
    "• Resume Clustering: Cluster resumes by projecting the text’s sentence embeddings and comparing their cosine similarity.\n",
    "• Dailygram: News aggregation website that ranks the importance of news and presents it in a summarized form.\n",
    "• AfterImage: Assist photo-editing tasks such as object removal, copying, translation & replacement using image processing and DL.\n",
    "ORGANIZING / LEADERSHIP\n",
    "AI Competition, IT Meet 2022, Kathmandu University August, 2022\n",
    "• Conducted a Machine-learning focused competition where 10 teams of undergraduate students (Total of 30 students) worked on training ML models for image and text classification; and performed data visualization.\n",
    "EDUCATION\n",
    "BSc. In Computer Science, Kathmandu University, Dhulikhel 45200, NP August 2018 – Present\n",
    "• Courses: Artificial Intelligence, Statistics & Probability, Calculus & Linear Algebra, Algorithms & Complexity, Database Systems\n",
    "• Electives: Machine Learning, Information Security\n",
    "Fusemachines AI Fellowship, Fuse.ai, Online January 2023 – Present\n",
    "• Currently involved in MicrodegreeTM in AI (Machine Learning) Course\n",
    "FastAI Deep Learning Course (Part2, 2022), Fast.ai, Online (Estimated completion: April 2023) October 2022 – Present\n",
    "• This online course focuses on implementing cutting-edge deep learning algorithms including Stable Diffusion and covers advanced topics such as contrastive learning, transformer models, auto-encoders, and CLIP embeddings, using plain PyTorch in Python.\n",
    "Nvidia Deep Learning Institute (DLI) Courses, Nvidia, Online (Self-paced) November 2022 – Present • Took three courses, with each course focusing on Inference / Model Deployment, Real-Time Video AI Application and the\n",
    "fundamentals of CUDA.\n",
    "Deep Learning Specialization deeplearning.ai, Online: Certificate Verification April 2018 – June 2018\n",
    "AWARDS & PUBLICATIONS\n",
    "U. Maskey, M. Bhatta, S. Bhatt, S. Dhungel, and B. K. Bal, “Nepali Encoder Transformers: An Analysis of Auto Encoding\n",
    "Transformer Language Models for Nepali Text Classification,” in Proceedings of the 1st Annual Meeting of the ELRA/ISCA Special Interest Group on Under-Resourced Languages, pp. 106–111. Available: https://aclanthology.org/2022.sigul-1.14\n",
    "SOFT SKILLS AND INTERESTS\n",
    "Language: English, Nepali, Conversational Japanese Hobbies: Piano | Typing | Gaming | Cardistry | Data Collection\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb673795",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_txt3 = '''\n",
    "What is Lorem Ipsum?\n",
    "Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\n",
    "\n",
    "Why do we use it?\n",
    "It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, content here', making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).\n",
    "\n",
    "\n",
    "Where does it come from?\n",
    "Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32.\n",
    "\n",
    "The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dcb578",
   "metadata": {},
   "source": [
    "# Overall document similarity using cosine scores (Matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ac81d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load spacy model for NER and keyword extraction\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load word2vec model\n",
    "w2v_model = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Define function to extract named entities and keywords from text\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    return [entity.text for entity in doc.ents] + [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "\n",
    "# Define function to compute cosine similarity between two vectors\n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# Define function to compute matching score between resume and job listing\n",
    "def compute_matching_score(resume, job_listing):\n",
    "    # Extract named entities and keywords from resume and job listing\n",
    "    resume_keywords = extract_keywords(resume)\n",
    "    job_keywords = extract_keywords(job_listing)\n",
    "#     print(f\"job_keywords:\\n\\n {job_keywords}\\n\\n\\n\")\n",
    "#     print(f\"resume_keywords:\\n\\n {resume_keywords}\\n\\n\\n\")\n",
    "    \n",
    "    # Compute average word2vec vector for resume and job listing keywords\n",
    "    resume_vec = np.mean([w2v_model.get_vector(keyword) for keyword in resume_keywords if keyword in w2v_model.key_to_index], axis=0)\n",
    "    job_vec = np.mean([w2v_model.get_vector(keyword) for keyword in job_keywords if keyword in w2v_model.key_to_index], axis=0)\n",
    "    \n",
    "    # Compute cosine similarity between resume and job listing vectors\n",
    "    similarity_score = cosine_similarity(resume_vec, job_vec)\n",
    "    \n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180aab27",
   "metadata": {},
   "source": [
    "# Skills matching by keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b684044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load spacy model for NER and keyword extraction\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load word2vec model\n",
    "w2v_model = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Define function to extract named entities and keywords from text\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    ##TODO: You need to extract only the keywords that are skills E.g. Python, Django, pytorch, etc\n",
    "    ## return [entity.text for entity in doc.ents] + [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "\n",
    "# Define function to compute cosine similarity between two vectors\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    ## TODO: You may replace cosine similarity with euclidean distance, or try both\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# Define function to compute matching score between resume and job listing\n",
    "def compute_matching_score(resume, job_listing):\n",
    "    # Extract named entities and keywords from resume and job listing\n",
    "    resume_keywords = extract_keywords(resume)\n",
    "    job_keywords = extract_keywords(job_listing)\n",
    "#     print(f\"job_keywords:\\n\\n {job_keywords}\\n\\n\\n\")\n",
    "#     print(f\"resume_keywords:\\n\\n {resume_keywords}\\n\\n\\n\")\n",
    "    \n",
    "    # Compute average word2vec vector for resume and job listing keywords\n",
    "    resume_vec = np.mean([w2v_model.get_vector(keyword) for keyword in resume_keywords if keyword in w2v_model.key_to_index], axis=0)\n",
    "    job_vec = np.mean([w2v_model.get_vector(keyword) for keyword in job_keywords if keyword in w2v_model.key_to_index], axis=0)\n",
    "    \n",
    "    # Compute cosine similarity between resume and job listing vectors\n",
    "    similarity_score = cosine_similarity(resume_vec, job_vec)\n",
    "    \n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b58e99",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61956d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching score\n",
      "\n",
      "Resume1\n",
      "Name: John S :  0.9101535081863403\n",
      "\n",
      "Resume2\n",
      "Utsav Maskey :  0.8020240664482117\n",
      "\n",
      "Resume2\n",
      "What is Lore :  0.6207307577133179\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "# job_listing = \"AI Engineer... Python... PyTorch... computer vision... communication skills\"\n",
    "# resume = \"I am an experienced software engineer with strong Python skills and expertise in computer vision. I also have excellent communication skills.\"\n",
    "\n",
    "score1 = compute_matching_score(resume_txt1, job_listing)\n",
    "score2 = compute_matching_score(resume_txt2, job_listing)\n",
    "score3 = compute_matching_score(resume_txt3, job_listing)\n",
    "print(f\"Matching score\\n\\nResume1{resume_txt1[:13]} :  {score1}\\n\\nResume2{resume_txt2[:13]} :  {score2}\\n\\nResume2{resume_txt3[:13]} :  {score3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075da96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
